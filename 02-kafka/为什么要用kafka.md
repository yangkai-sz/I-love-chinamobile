# 之前一直不理解，为什么要用kafka？尤其是在elk的架构下。
然后看了这篇文章，感觉不错：https://www.jianshu.com/p/c66c9b5b4ec2
```
引入了消息队列机制，位于各个节点上的Logstash Agent先将数据/日志传递给Kafka（或者Redis），并将队列中消息或数据间接传递给Logstash，Logstash过滤、分析后将数据传递给Elasticsearch存储。最后由Kibana将日志和数据呈现给用户。因为引入了Kafka（或者Redis）,所以即使远端Logstash server因故障停止运行，数据将会先被存储下来，从而避免数据丢失。这种架构适合于较大集群的解决方案，但由于Logstash中心节点和Elasticsearch的负荷会比较重，可将他们配置为集群模式，以分担负荷，这种架构的优点在于引入了消息队列机制，均衡了网络传输，从而降低了网络闭塞尤其是丢失数据的可能性，但依然存在Logstash占用系统资源过多的问题。

作者：mysia
链接：https://www.jianshu.com/p/c66c9b5b4ec2
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
```
# 终于理解为什么
因为我原来理解的是：由其他程序来生成数据写入到文件里，然后由filebeat、logstash采集，采集的是文件，不需要缓冲，因为文件一直都在，不需要kafka。

但是，如果logstash采集syslog的数据，如果你的logstash挂掉了，那么数据必然会丢失。

# 什么是流计算
之前一直很懵逼，慢慢用了logstash明白了一些，我用logstash的grok、mutate功能，感觉像是用了流计算。

* https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/input/stdin.html    logstash权威介绍
* https://www.cntofu.com/book/52/filter/mutate.md   logstash权威介绍
* filters/mutate 插件是 Logstash 另一个重要插件。它提供了丰富的基础类型数据处理能力。包括类型转换，字符串处理和字段处理等。
* 我用mutate插件，对原始文本分割处理，最终数据像json格式一样，入到es里。（vssh）

## 联想，以及流处理框架，尤其是原因4
在我shell审计的过程中，如果用filebeat采集了vssh日志之后，能够跟我的审计规则匹配之后再写入es，这样就是流处理、实时处理。如果我先写入es、然后定时去查下es、然后update数据，显然不是一个好的办法啊。。。

Flink以数据并行和流水线方式执行任意流数据程序，Flink的流水线运行时系统可以执行批处理和流处理程序。此外，Flink的运行时本身也支持迭代算法的执行。
```
### 下面是使用流处理的一些次要原因。
原因1: 有些数据自然地以永无止境的事件流出现。要进行批处理，需要存储它、在某个时间停止数据收集并处理数据。然后你必须执行下一批操作，然后担心跨多个批进行聚合。相比之下，流处理永无止境的数据流更优雅、更自然。你可以检测模式、检查结果、查看多个焦点级别，还可以轻松地同时查看来自多个流的数据。
流处理天然地适合时间序列数据和随时间变化的检测模式。例如，如果你试图检测无限流中的web会话的长度（这是尝试检测序列的示例）。分批处理非常困难，因为某些会话将分为两批。流处理可以很容易地处理这个问题。
如果你退一步考虑，最连续的数据序列是时间序列数据：交通传感器、健康传感器、事务日志、活动日志等。几乎所有IoT数据都是时间序列数据。因此，使用天然适用的编程模型是有意义的。
原因2: 批处理允许数据建立并尝试同时处理它们，而流处理立即处理进来的数据，因此处理随时间扩展。因此，流处理可以使用比批处理少得多的硬件。此外，流处理还允许通过系统负载削减进行近似查询处理。因此，流处理天然适合于近似答案足够多的用例。
原因3: 有时数据很大，甚至无法存储。流处理允许你处理大型消防马型数据，并且只保留有用的位。
原因4: 最后，有许多流数据可用（例如，客户事务、活动、网站访问），并且随着IoT用例（各种传感器）的增长，这些数据将更快。流式是一种更自然的模型，可以考虑和编程这些用例。

作者：willcat
链接：https://juejin.im/post/5c1a3eb8f265da61137f3a01
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
```

# 如何通俗的理解kafa
这篇文章写得很好：https://www.cnblogs.com/sujing/p/10960832.html
## 便利店（菜鸟驿站）的案例举的特别的好！
* 快递小哥————我，请假回家，不现实！
* 快递小哥————便利店（代收快递）————我
```
在上面例子中，“快递小哥”和“买女朋友的我”就是需要交互的两个系统，小芳便利店就是我们本文要讲的-“消息中间件”。总结下来小芳便利店（消息中间件）出现后有如下好处：
　　1、 解耦
　　快递小哥手上有很多快递需要送，他每次都需要先电话一一确认收货人是否有空、哪个时间段有空，然后再确定好送货的方案。这样完全依赖收货人了！如果快递一多，快递小哥估计的忙疯了……如果有了便利店，快递小哥只需要将同一个小区的快递放在同一个便利店，然后通知收货人来取货就可以了，这时候快递小哥和收货人就实现了解耦！

　　2、 异步
　　快递小哥打电话给我后需要一直在你楼下等着，直到我拿走你的快递他才能去送其他人的。快递小哥将快递放在小芳便利店后，又可以干其他的活儿去了，不需要等待你到来而一直处于等待状态。提高了工作的效率。

　　3、 削峰
　　假设双十一我买了不同店里的各种商品，而恰巧这些店发货的快递都不一样，有中通、圆通、申通、各种通等……更巧的是他们都同时到货了！中通的小哥打来电话叫我去北门取快递、圆通小哥叫我去南门、申通小哥叫我去东门。我一时手忙脚乱……

　　我们能看到在系统需要交互的场景中，使用消息队列中间件真的是好处多多，基于这种思路，就有了丰巢、菜鸟驿站等比小芳便利店更专业的“中间件”了。
```
## 基本概念介绍
```
Producer：Producer即生产者，消息的产生者，是消息的入口。
kafka cluster：
Broker：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号，如图中的broker-0、broker-1等……
Topic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。
Partition：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！
Replication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。
Message：每一条发送的消息主体。
Consumer：消费者，即消息的消费方，是消息的出口。
Consumer Group：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！
Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。
```
hive是数据仓库系统，基于mapreduce的，用的hsql。
