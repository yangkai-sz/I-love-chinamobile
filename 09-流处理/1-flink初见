在基于elk做日志分析的时候，我们都是等日志积累到一定程度（比如1天）进行批处理，然后生成文件，由logstash卸乳elasticsearch，同时也会发送v消息告警给我和当事人。

随着我搭建了filebeat+logstash+elasticsearch，实时去采集vssh日志（自演堡垒机），问题就来了，我的shell审计规则（高危命令，如执行黑客指令，授予777权限等）就需要去查下es、然后更新es的数据来实现。显然这不是一个好的处理，我自己也觉得很别扭。

流处理这个概念，以前一只很懵逼，根本不知道什么是流、流处理。结合我的自演堡垒机日志审计的过程，我明白了，我实时采集的堡垒机日志，就是所谓的“流”，如果我能实时处理，就可以实时的告警了。（其实最初的时候，为了提升时效性，我想着每10分钟去查下一下es，然后用python去处理查询结果、匹配审计规则、然后发送v消息告警。这样的我的时效性是10分钟内的）

同时，我们的业务后台审计日志的架构，也是跟上面差不多，只是多了kafka。但还是批处理，每天凌晨跑一边审计规则。但在有些审计场景下，你不立即发送告警信息给当事人，第二天再发，意义已经不大了，比如一个高危操作、满足触发告警条件，你当时不发、第二天发，卧槽，人家可能都忘记做了什么操作了。就算是恶意操作、黑客入侵，你第二天就告诉对应账号的owner，是不是太迟了？？？

明白了流处理的概念之后，就想办法去学习流处理框架，先买了本spark，还没咋看，发现spark不行（不好）；又上网查查说storm比较成熟、主流、比较屌，又买了本storm，刚看了两章，发现现在一线互联网公司的流处理架构，都在从storm往flink上迁移，理由是：flink更快、更能精准的保证消息只处理一次（exactly-once），这两个特性，在一线互联网公司，特别重要。但我看storm书上说，storm原来的机制是保证每个消息至少被处理一下，言外之意，那tmd就是可能会被处理多次，在有些特殊的业务场景下，那肯定是不行的，但在storm的0.7.0中引入了事务性拓扑，解决了这个问题。但人们还是要用flink，为毛？不懂。。。。

参考这个人的博格，搞了一下，摸索一下：https://blog.csdn.net/weixin_39984161/article/details/93056566

wordcount是一个典型的案例，通过分析，这种场景还是有一点的弊端、还是要结合es来使用，比如我统计3m内的出现某个单词的数量，我分割时间的时候，还是会把“时间分割”，比如我一直输入字母a，输入时间为8秒，那么将会输出a：3（输入了3次）；a：5（输入了5次）；a：4（输入了4次）。比如我想要扩大时间范围，比如1个小时，那么这个时候还是需要用elasticsearch，比如这样子：
GET self*/_search
{
  "_source": ["offset"], 
  "query": {
    "match_all": {}
  }
}
上面执行查询测试一下。然后下面去根据时间段去搜索要想的值，如sum。

GET self*/_search?size=0
{
  "query": {
    "bool": {
      "must": [
        {"match_all": {}}
      ],"filter": {
        "range": {
          "FIELD": {
            "gte": 10,
            "lte": 20
          }
        }
      }
    }
  }, 
  "aggs": {
    "NAME": {
      "sum": {
        "field": "offset"
      }
    }
  }
}

后面我又想了一下，可能更多的场景是这样子的，原来是按照3m，现在我按照1小时来统计阈值，应该是数据库的那种count、groupby的查询，在es就是agg、terms，如下：
GET vssh--2019.07/_search
{
  "size": 0, 
  "aggs": {
    "qiuhe": {
      "terms": {
        "field": "log_operator.keyword"
        , "size": 5,
        "order": {
          "_count": "desc"
        }
      }
    }
  }
}
ok，就这样子吧。2020-3-28，星期六vi-vo。
